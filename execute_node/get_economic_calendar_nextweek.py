import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import json
from collections import defaultdict

def extract_star_rating_with_title(td):
    '''
    ì¤‘ìš”ë„ â˜…ë§Œ ì¶”ì¶œ(ì˜ˆ: â˜…â˜†â˜†, â˜…â˜…â˜†, â˜…â˜…â˜…)
    '''
    full = len(td.find_all("i", class_="grayFullBullishIcon"))
    stars = "â˜…" * full + "â˜†" * (3 - full)
    # title = td.get("title", "").strip() - (ì¤‘ìš”ë„ ì„¤ëª…)
    return stars

async def scroll_until_done(page, pause_time=1200, max_scrolls=60, stable_threshold=4):
    """
    ì‹¤ì  ìº˜ë¦°ë”ì—ì„œ ìŠ¤í¬ë¡¤ì„ ë°˜ë³µí•˜ì—¬ ëª¨ë“  ë°ì´í„°ê°€ ë¡œë”©ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
    """
    prev_count = 0
    stable_rounds = 0

    for i in range(max_scrolls):
        await page.mouse.wheel(0, 10000)
        await page.wait_for_timeout(pause_time)

        # tbody ì•„ë˜ì˜ tr ê°œìˆ˜ ì¸¡ì •
        row_count = await page.evaluate("""
            () => document.querySelectorAll('#earningsCalendarData tbody tr').length
        """)
        # print(f"[{i+1}] Row count: {row_count}")

        if row_count == prev_count:
            stable_rounds += 1
        else:
            stable_rounds = 0

        if stable_rounds >= stable_threshold:
            # print("âœ… ë” ì´ìƒ ë¡œë”©ë˜ëŠ” í•­ëª© ì—†ìŒ. ìŠ¤í¬ë¡¤ ì¢…ë£Œ.")
            break

        prev_count = row_count

async def scrape_us_events():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
        page = await context.new_page()

        await page.goto("https://kr.investing.com/economic-calendar/", wait_until="domcontentloaded")
        await page.wait_for_selector("#timeFrame_nextWeek", timeout=5000)

        # ğŸ”„ 'ë‹¤ìŒ ì£¼' ë²„íŠ¼ í´ë¦­"
        await page.click("#timeFrame_nextWeek")
        await page.wait_for_selector("td.theDay", timeout=7000)

        # âœ… í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤í•´ì„œ ì „ì²´ ë°ì´í„° ë¡œë”©
        await scroll_until_done(page, pause_time=600)
        
        html = await page.content()
        await browser.close()

    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table", id="economicCalendarData")

    # í•­ëª©ì€ ê³ ì •ì´ë‹ˆê¹Œ ìˆ˜ë™ìœ¼ë¡œ ê¸°ì…
    headers = ["ì‹œê°„", "ì¤‘ìš”ì„±", "ì´ë²¤íŠ¸", "ì‹¤ì œ", "ì˜ˆì¸¡", "ì´ì „"]
    result_by_date = defaultdict(list)
    current_date = None

    for row in table.select("tbody tr"):
        
        # âœ… ë‚ ì§œ ì¶”ì¶œì€ <tr> ë‚´ë¶€ì˜ <td>ë¥¼ í™•ì¸í•´ì•¼ í•¨
        td = row.find("td", class_="theDay")
        if td:
            current_date = td.get_text(strip=True)
            continue

        # ì´ë²¤íŠ¸ í–‰: class="js-event-item", ì´ë²¤íŠ¸ê°€ ì•„ë‹Œê²ƒë“¤=ë‚ ì§œ
        if "js-event-item" not in row.get("class", []):
            continue
        
        # âœ… ë¯¸êµ­ë§Œ í•„í„°ë§
        flag = row.select_one("span.ceFlags")
        if not flag or "United_States" not in flag.get("class", []):
            continue
        
        cols = row.select("td")
        # ë§¨ë’¤ ìš”ì†ŒëŠ” ì•Œë¦¼ ìƒì„± => X
        values = [col.get_text(strip=True) for col in cols][:-1]
        
        # âœ… ì¤‘ìš”ì„± tdì—ì„œ ë³„ + ì„¤ëª… ì¶”ì¶œ
        importance_td = cols[2]
        importance = extract_star_rating_with_title(importance_td)
        values[2] = importance  # ì„¸ ë²ˆì§¸ ìš”ì†Œ êµì²´

        # ì´ë²¤íŠ¸ row ì²˜ë¦¬
        record = dict(zip(headers, values))
        
        if current_date:
            result_by_date[current_date].append(record)
    
    return result_by_date

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    events = asyncio.run(scrape_us_events())
    print(json.dumps(events, indent=2, ensure_ascii=False))


