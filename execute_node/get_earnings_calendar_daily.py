import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import json
from collections import defaultdict
import re

def parse_company_and_ticker(text):
    """
    'íšŒì‚¬ëª…(í‹°ì»¤)' í˜•íƒœì˜ ë¬¸ìì—´ì—ì„œ ë¶„ë¦¬
    ì˜ˆ: "EpicQuest Education International(EEIQ)" â†’ ("EpicQuest Education International", "EEIQ")
    """
    match = re.match(r"(.+?)\s*\((.+?)\)", text)
    if match:
        company_name = match.group(1).strip()
        ticker = match.group(2).strip()
        return company_name, ticker
    return text.strip(), None

def clean_prediction_value(text):
    """
    '/  5.57M' â†’ '5.57M'
    """
    return text.replace("/", "").strip()

async def scrape_us_events():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context()
        page = await context.new_page()

        await page.goto("https://investing.com/earnings-calendar/", wait_until="domcontentloaded")
        await page.wait_for_selector("#timeFrame_yesterday", timeout=5000)

        # ğŸ”„ 'ì–´ì œ' ë²„íŠ¼ í´ë¦­"
        await page.click("#timeFrame_yesterday")
        await page.wait_for_selector("td.theDay", timeout=7000)

        html = await page.content()
        await browser.close()

    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table", id="earningsCalendarData")

    # í•­ëª©ì€ ê³ ì •ì´ë‹ˆê¹Œ ìˆ˜ë™ìœ¼ë¡œ ê¸°ì…
    headers = ["íšŒì‚¬", "ì£¼ë‹¹ìˆœì´ìµ(EPS)", "ì£¼ë‹¹ìˆœì´ìµ_ì˜ˆì¸¡", "ë§¤ì¶œ(Revenue)", "ë§¤ì¶œ_ì˜ˆì¶•", "ì´ ì‹œê°€"]
    result_by_date = defaultdict(list)
    current_date = None

    for row in table.select("tbody tr"):
        
        # âœ… ë‚ ì§œ ì¶”ì¶œì€ <tr> ë‚´ë¶€ì˜ <td>ë¥¼ í™•ì¸í•´ì•¼ í•¨
        td = row.find("td", class_="theDay")
        if td:
            current_date = td.get_text(strip=True)
            continue
        
        # ì´ë²¤íŠ¸ í–‰: <td> ìš”ì†Œë“¤ë§Œ ìˆìŒ. Classë¥¼ ê±¸ëŸ¬ë‚¼ í•„ìš”ê°€ì—†ìŒ

        # âœ… ë¯¸êµ­ë§Œ í•„í„°ë§(ì‹¤ì  ì‚¬ì´íŠ¸ì—ì„  Namingì´ ë‹¤ë¦„, ceFlags)
        flag = row.select_one("span.ceFlags")
        if not flag or "USA" not in flag.get("class", []):
            continue
        
        cols = row.select("td")
        # ìš”ì†Œ(êµ­ê°€, ì‹œê°„, ì•Œë¦¼) => X
        values = [col.get_text(strip=True) for col in cols][1:-2]

        # íšŒì‚¬, í‹°ì»¤
        company_raw = values[0]
        company_name, ticker = parse_company_and_ticker(company_raw)
        values[0] = company_name

        # / ê³µë°± ì œê±°
        values[2] = clean_prediction_value(values[2])
        values[-2] = clean_prediction_value(values[-2])

        # ì´ë²¤íŠ¸ row ì²˜ë¦¬
        record = dict(zip(headers, values))
        if ticker:
            record["í‹°ì»¤"] = ticker
        else:
            record["í‹°ì»¤"] = None
        
        if current_date:
            result_by_date[current_date].append(record)
    
    return result_by_date

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    events = asyncio.run(scrape_us_events())
    # print(f"\nâœ… ì´ ì¶”ì¶œ ì´ë²¤íŠ¸ ìˆ˜: {len(events)}")
    # print(json.dumps(events, indent=2, ensure_ascii=False))\
    print(json.dumps(events, indent=2, ensure_ascii=False))
