import asyncio
from playwright.async_api import async_playwright, TimeoutError
from bs4 import BeautifulSoup
import json
from collections import defaultdict

# ë³„ì ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼)
def extract_star_rating(td):
    '''
    ì¤‘ìš”ë„ â˜…ë§Œ ì¶”ì¶œ(ì˜ˆ: â˜…â˜†â˜†, â˜…â˜…â˜†, â˜…â˜…â˜…)
    '''
    full = len(td.find_all("i", class_="grayFullBullishIcon"))
    stars = "â˜…" * full + "â˜†" * (3 - full)
    return stars

async def scrape_and_parse_tab(page, tab_selector):
    """
    ì£¼ì–´ì§„ tab_selectorë¥¼ í´ë¦­í•˜ê³  í•´ë‹¹ íƒ­ì˜ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    # print(f"ğŸ”„ {tab_selector} íƒ­ì„ í´ë¦­í•˜ê³  ë°ì´í„°ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤...")
    await page.click(tab_selector)
    
    try:
        # ë°ì´í„° ë¡œë”©ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸° (ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ì¡°ì ˆ ê°€ëŠ¥)
        await page.wait_for_selector("td.theDay", timeout=10000)
    except TimeoutError:
        print(f"âš ï¸ {tab_selector} íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return defaultdict(list)

    html = await page.content()
    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table", id="economicCalendarData")

    if not table:
        return defaultdict(list)

    headers = ["ì‹œê°„", "ì¤‘ìš”ì„±", "ì´ë²¤íŠ¸", "ì‹¤ì œ", "ì˜ˆì¸¡", "ì´ì „"]
    result_by_date = defaultdict(list)
    current_date = None

    for row in table.select("tbody tr"):
        if "js-event-item" not in row.get("class", []):
            td = row.find("td", class_="theDay")
            if td:
                current_date = td.get_text(strip=True)
            continue

        flag = row.select_one("span.ceFlags")
        if not flag or "United_States" not in flag.get("class", []):
            continue
        
        cols = row.select("td")

        event_time = cols[0].get_text(strip=True)

        # 'ì˜¤ëŠ˜' íƒ­(#timeFrame_today)ì¼ ê²½ìš°, 08:00ë¥¼ ì´ˆê³¼í•˜ëŠ” ë°ì´í„°ëŠ” ë¬´ì‹œí•˜ê³  ë°˜ë³µ ì¤‘ë‹¨
        if tab_selector == "#timeFrame_today":
            if event_time > "08:00":
                # print(f"âœ… 'ì˜¤ëŠ˜' íƒ­ì—ì„œ 08:00 ì´í›„ ë°ì´í„°({event_time})ì´ë¯€ë¡œ ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
        
        # 'ì–´ì œ' íƒ­(#timeFrame_yesterday)ì¼ ê²½ìš°, 08:00 ì´ì „ ë°ì´í„°ëŠ” ê±´ë„ˆë›°ê¸° (ì¤‘ë³µ ë°©ì§€)
        if tab_selector == "#timeFrame_yesterday":
            if event_time <= "08:00":
                # ì´ ì‹œê°„ëŒ€ ë°ì´í„°ëŠ” ì´ì „ ì‹¤í–‰ ì‹œ 'ì˜¤ëŠ˜' íƒ­ì—ì„œ ì´ë¯¸ ìˆ˜ì§‘í–ˆìœ¼ë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.
                continue

        if len(cols) < len(headers):
            continue

        values = [col.get_text(strip=True) for col in cols][:-1]
        
        importance_td = cols[2]
        importance = extract_star_rating(importance_td)
        values[2] = importance

        record = dict(zip(headers, values))
        
        if current_date:
            result_by_date[current_date].append(record)
            
    return result_by_date

async def scrape_us_events_combined():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context()
        page = await context.new_page()

        await page.goto("https://kr.investing.com/economic-calendar/", wait_until="domcontentloaded")
        
        # 'ì–´ì œ' íƒ­ ë°ì´í„° ìŠ¤í¬ë˜í•‘
        yesterday_events = await scrape_and_parse_tab(page, "#timeFrame_yesterday")
        
        # 'ì˜¤ëŠ˜' íƒ­ ë°ì´í„° ìŠ¤í¬ë˜í•‘
        today_events = await scrape_and_parse_tab(page, "#timeFrame_today")

        await browser.close()

        # ë‘ ë”•ì…”ë„ˆë¦¬ ê²°ê³¼ ë³‘í•©
        merged_events = yesterday_events.copy()
        for date, events in today_events.items():
            merged_events[date].extend(events)

        return merged_events

# --- ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    # í•œêµ­ ì‹œê°„ 2025ë…„ 9ì›” 4ì¼ ì˜¤ì „ì— ì‹¤í–‰í–ˆë‹¤ê³  ê°€ì •
    events = asyncio.run(scrape_us_events_combined())
    # print("\nâœ… 'ì–´ì œ'ì™€ 'ì˜¤ëŠ˜' íƒ­ì—ì„œ ìˆ˜ì§‘ëœ ëª¨ë“  ë¯¸êµ­ ì´ë²¤íŠ¸:")

    print(json.dumps(events, indent=2, ensure_ascii=False))

